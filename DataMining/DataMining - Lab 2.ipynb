{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data Mining - MSDS 7331 - Thurs 6:30, Summer 2016\n",
    "\n",
    "Team 3 (AKA Team Super Awesome):  Sal Melendez, Rahn Lieberman, Thomas Rogers\n",
    "\n",
    "Github page:\n",
    "https://github.com/RahnL/DataScience-SMU/tree/master/DataMining\n",
    "\n",
    "Note: Code borrowed heavily from Eric Larson's github pages for this class.\n",
    "https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "\n",
    "Code also borrowed from other projects we're working on using the same dataset.\n",
    "\n",
    "https://github.com/RahnL/DataScience-SMU/blob/master/DataMining/DataMining-MiniLab1-Lieberman-Melendez-Rogers.ipynb\n",
    "https://github.com/rlshuhart/MSDS6210-Immersion_Project/blob/master/Study/Closing%20the%20Gap%20Study%20Revisited.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* Intro\n",
    "* Data Cleanup and Reduction\n",
    "\n",
    "###Clean the rest of this up before submitting.\n",
    "* Logistical Regression\n",
    "* KNN, decision tree- Rahn\n",
    "* Random Forest - Sal\n",
    "* Neural net - Thomas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "\n",
    "Our team has selected the 2014 Behavioral Risk Factor Surveillance System data (BRFSS), from the Center for Disease Control and prevention (CDC), to attempt to understand the relationship between quality of health and a number of behavioral, demographic and environmental factors. \n",
    "\n",
    "The purpose of the BRFSS project is to survey a large population of Americans on a wide range of topics to inform policy, research and healthcare delivery. The same or similar questions are asked each year and the resulting dataset gives not only a broad, comprehensive view of health quality in the United States, but it also provides a longitudinal view on how quality of care (among other factors) is changing over time.\n",
    "\n",
    "There are 279 variables in the dataset and over 460,000 surveys completed. The sheer breadth and complexity of this data, with missing, weighted and calculated variables requires a clear and distinct question of interest and some sense of what variables might help answer the question. We have chosen to focus on one particular question in the survey as our response variable and will attempt to better understand the impact reported behaviors have on responses to that question. \n",
    "\n",
    "Our response variable becomes the answer to the following question on quality of health: \"Would you say that in general your health is: (1) excellent, (2) very good, (3) good, (4) fair, (5) poor?\" (section 1.1, column 80)\n",
    "\n",
    "We reduce the 279 variables to focus on those related to behavioral survey questions. The corresponding variables from the questions related to behavior number 30, so our dataset is roughly 450,000 rows by 30 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# plot graphs in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahnl\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (120) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting length is 464664 \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 464664 entries, 0 to 464663\n",
      "Columns: 279 entries, _STATE to RCSBIRTH\n",
      "dtypes: float64(226), int64(52), object(1)\n",
      "memory usage: 989.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENUM</th>\n",
       "      <th>...</th>\n",
       "      <th>_FOBTFS</th>\n",
       "      <th>_CRCREC</th>\n",
       "      <th>_AIDTST3</th>\n",
       "      <th>_IMPEDUC</th>\n",
       "      <th>_IMPMRTL</th>\n",
       "      <th>_IMPHOME</th>\n",
       "      <th>RCSBRAC1</th>\n",
       "      <th>RCSRACE1</th>\n",
       "      <th>RCHISLA1</th>\n",
       "      <th>RCSBIRTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1172014</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000001</td>\n",
       "      <td>2014000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1072014</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000002</td>\n",
       "      <td>2014000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1092014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000003</td>\n",
       "      <td>2014000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1072014</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000004</td>\n",
       "      <td>2014000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1162014</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000005</td>\n",
       "      <td>2014000005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  FMONTH    IDATE  IMONTH  IDAY  IYEAR  DISPCODE       SEQNO  \\\n",
       "0       1       1  1172014       1    17   2014      1100  2014000001   \n",
       "1       1       1  1072014       1     7   2014      1100  2014000002   \n",
       "2       1       1  1092014       1     9   2014      1100  2014000003   \n",
       "3       1       1  1072014       1     7   2014      1100  2014000004   \n",
       "4       1       1  1162014       1    16   2014      1100  2014000005   \n",
       "\n",
       "         _PSU  CTELENUM    ...     _FOBTFS  _CRCREC  _AIDTST3  _IMPEDUC  \\\n",
       "0  2014000001       1.0    ...         2.0      1.0       2.0         5   \n",
       "1  2014000002       1.0    ...         2.0      2.0       2.0         4   \n",
       "2  2014000003       1.0    ...         2.0      2.0       2.0         6   \n",
       "3  2014000004       1.0    ...         2.0      1.0       2.0         6   \n",
       "4  2014000005       1.0    ...         2.0      1.0       2.0         5   \n",
       "\n",
       "   _IMPMRTL  _IMPHOME  RCSBRAC1  RCSRACE1  RCHISLA1  RCSBIRTH  \n",
       "0         1         1       NaN       NaN       NaN       NaN  \n",
       "1         1         1       NaN       NaN       NaN       NaN  \n",
       "2         1         1       NaN       NaN       NaN       NaN  \n",
       "3         3         1       NaN       NaN       NaN       NaN  \n",
       "4         1         1       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, and do some initial cleanup.\n",
    "\n",
    "df = pd.read_csv(\"data/LLCP2014XPT.txt\", sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "df.head()\n",
    "\n",
    "print(\"Starting length is %.f \" % len(df))\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reduction and Pre-processing\n",
    "\n",
    "Because we're interested in the relationship between behaviors, demographics and other factors, and the impact they have on general health quality, we'll reduce the data frame down to those variables we think will have the biggest impact, including:\n",
    "\n",
    "#### Behaviors:\n",
    "- Whether someone smokes or not (represented by _SMOKER3)\n",
    "- Physical activity (represented by PHYSHLTH)\n",
    "\n",
    "#### Demographics:\n",
    "- Age (represented by _AGE_G)\n",
    "- Education level (represented by EDUCA)\n",
    "- Income level (represented by _INCOMG)\n",
    "- Race (represented by _IMPRACE, an imputed value based on the initial data ste)\n",
    "\n",
    "#### Other Factors:\n",
    "- The cost of health care (represented by MEDCOST)\n",
    "- Health coverage (represented by HLTHPLN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Age 18 to 64 - Excludes 65 or older, refused, or missing\n",
    "df = df[df['_AGE65YR'] == 1].drop('_AGE65YR', axis=1)\n",
    "\n",
    "# Exclude blank, 'Don't know', 'Not Sure', or 'Refused'\n",
    "df = df[((df['GENHLTH'].notnull()) & (~df['GENHLTH'].isin([7,9])))] \n",
    "\n",
    "# Reduce Ethnicity to White, Black, or Hispanic (ex. Asian 2%, American Indian/Alaskan Native 1.55%, other 2.8%)\n",
    "df = df[df['_IMPRACE'].isin([1,2,5])]\n",
    "# Has Health plan --Excludes 'Don't know', 'Not Sure', or 'Refused'. drops .6%\n",
    "df = df[df['HLTHPLN1'].isin([1,2])]\n",
    "\n",
    "# Translate GENHLTH to binary classification of\n",
    "# Combining the “excellent”, “very good” and “good” responses as measures of “good or better” (1) health \n",
    "# and the “fair” and “poor” measures as “fair and poor” (0).\n",
    "df.loc[(df['GENHLTH'] < 4), 'health'] = 1\n",
    "df.loc[(df['GENHLTH'] >= 4), 'health'] = 0\n",
    "\n",
    "# Extract survey year from sequence. IYEAR sometimes went into the next year. \n",
    "# This is one way to put designate the year of the data publication\n",
    "# Also, if we add  other years to the data, this seperates it.\n",
    "df['Rec_Year'] = df['SEQNO'].astype(str).str[:4].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahnl\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\rahnl\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 231507 entries, 2 to 464663\n",
      "Data columns (total 9 columns):\n",
      "health      231507 non-null float64\n",
      "_SMOKER3    231507 non-null float64\n",
      "PHYSHLTH    231507 non-null float64\n",
      "_AGE_G      231507 non-null int64\n",
      "EDUCA       231507 non-null float64\n",
      "_INCOMG     231507 non-null float64\n",
      "MEDCOST     231507 non-null float64\n",
      "HLTHPLN1    231507 non-null int64\n",
      "_IMPRACE    231507 non-null int64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 17.7 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>_AGE_G</th>\n",
       "      <th>EDUCA</th>\n",
       "      <th>_INCOMG</th>\n",
       "      <th>MEDCOST</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>_IMPRACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    health  _SMOKER3  PHYSHLTH  _AGE_G  EDUCA  _INCOMG  MEDCOST  HLTHPLN1  \\\n",
       "2      1.0       3.0      88.0       4    6.0      5.0      2.0         1   \n",
       "6      1.0       3.0       2.0       5    6.0      5.0      2.0         1   \n",
       "7      1.0       4.0       3.0       5    4.0      1.0      2.0         1   \n",
       "9      1.0       2.0       1.0       3    5.0      5.0      2.0         1   \n",
       "12     1.0       4.0      88.0       3    6.0      5.0      2.0         1   \n",
       "13     1.0       3.0      88.0       5    6.0      3.0      2.0         1   \n",
       "22     0.0       4.0      22.0       4    5.0      2.0      1.0         1   \n",
       "24     1.0       1.0      88.0       2    5.0      1.0      1.0         1   \n",
       "25     0.0       1.0      30.0       3    2.0      2.0      1.0         2   \n",
       "26     1.0       4.0      88.0       5    5.0      5.0      2.0         1   \n",
       "27     1.0       4.0       1.0       5    5.0      5.0      2.0         1   \n",
       "31     1.0       4.0      88.0       4    5.0      5.0      2.0         1   \n",
       "38     1.0       4.0      88.0       4    5.0      5.0      2.0         1   \n",
       "39     1.0       4.0      88.0       5    4.0      4.0      2.0         1   \n",
       "41     1.0       4.0      88.0       4    5.0      3.0      2.0         1   \n",
       "43     0.0       3.0      88.0       5    6.0      2.0      2.0         1   \n",
       "45     0.0       1.0      30.0       5    4.0      2.0      1.0         1   \n",
       "47     1.0       4.0      88.0       5    5.0      2.0      2.0         1   \n",
       "48     1.0       4.0      88.0       4    5.0      5.0      2.0         1   \n",
       "53     1.0       4.0      88.0       5    3.0      2.0      2.0         2   \n",
       "\n",
       "    _IMPRACE  \n",
       "2          1  \n",
       "6          1  \n",
       "7          1  \n",
       "9          1  \n",
       "12         1  \n",
       "13         1  \n",
       "22         1  \n",
       "24         1  \n",
       "25         1  \n",
       "26         1  \n",
       "27         1  \n",
       "31         1  \n",
       "38         1  \n",
       "39         1  \n",
       "41         1  \n",
       "43         1  \n",
       "45         1  \n",
       "47         1  \n",
       "48         1  \n",
       "53         1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the variables we want to look at to a new DF, and a little more cleanup\n",
    "df_reduced = df[['health','_SMOKER3','PHYSHLTH','_AGE_G','EDUCA','_INCOMG','MEDCOST','HLTHPLN1','_IMPRACE']]\n",
    "\n",
    "# Cleanup\n",
    "df_reduced.replace(7,np.nan, inplace=True)  #replace the \"refused\" answer choice\n",
    "df_reduced.replace(9, np.nan, inplace=True) #replace the 'Don't Know' choice\n",
    "df_reduced = df_reduced.dropna() # this drops those that were the refused/don't know.\n",
    "\n",
    "df_reduced.info()\n",
    "df_reduced.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='health', dtype='float64',\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(df_reduced) \n",
    "OneHotEncoder(categorical_features='health', dtype='float64', handle_unknown='error', n_values='auto', sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>_AGE_G</th>\n",
       "      <th>EDUCA</th>\n",
       "      <th>_INCOMG</th>\n",
       "      <th>MEDCOST</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>_IMPRACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    health  _SMOKER3  PHYSHLTH  _AGE_G  EDUCA  _INCOMG  MEDCOST  HLTHPLN1  \\\n",
       "2      1.0       3.0      88.0       4    6.0      5.0      2.0         1   \n",
       "6      1.0       3.0       2.0       5    6.0      5.0      2.0         1   \n",
       "7      1.0       4.0       3.0       5    4.0      1.0      2.0         1   \n",
       "9      1.0       2.0       1.0       3    5.0      5.0      2.0         1   \n",
       "12     1.0       4.0      88.0       3    6.0      5.0      2.0         1   \n",
       "13     1.0       3.0      88.0       5    6.0      3.0      2.0         1   \n",
       "22     0.0       4.0      22.0       4    5.0      2.0      1.0         1   \n",
       "24     1.0       1.0      88.0       2    5.0      1.0      1.0         1   \n",
       "25     0.0       1.0      30.0       3    2.0      2.0      1.0         2   \n",
       "26     1.0       4.0      88.0       5    5.0      5.0      2.0         1   \n",
       "\n",
       "    _IMPRACE  \n",
       "2          1  \n",
       "6          1  \n",
       "7          1  \n",
       "9          1  \n",
       "12         1  \n",
       "13         1  \n",
       "22         1  \n",
       "24         1  \n",
       "25         1  \n",
       "26         1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Here, we are performing a logistic regression test to see how accurately we can predict health based on our chosen variables.\n",
    "\n",
    "We do 3-fold cross validation, using an 80/20 split for training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(231507, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# rerun with all variables, filling NaN values with zero\n",
    "# Create a copy of the dataframe, so the original is still available for other models in the notebook\n",
    "df_logreg = df_reduced\n",
    "df_logreg = df_logreg.fillna(value=0)\n",
    "\n",
    "#... setup x, y\n",
    "if 'health' in df_logreg:\n",
    "    y = df_logreg['health'].values # get the labels we want\n",
    "    del df_logreg['health'] # get rid of the class label\n",
    "\n",
    "X = df_logreg.values # use everything else to predict!\n",
    "\n",
    "# do the cross validation\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "print (cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('====Iteration', 0, ' ====')\n",
      "('accuracy', 0.8657077448058399)\n",
      "('confusion matrix\\n', array([[ 2268,  4852],\n",
      "       [ 1366, 37816]]))\n",
      "('\\nAverage accuracy: ', 0.8657077448058399)\n",
      "('====Iteration', 1, ' ====')\n",
      "('accuracy', 0.86421752840050103)\n",
      "('confusion matrix\\n', array([[ 2324,  4897],\n",
      "       [ 1390, 37691]]))\n",
      "('\\nAverage accuracy: ', 0.86496263660317041)\n",
      "('====Iteration', 2, ' ====')\n",
      "('accuracy', 0.86458468316703385)\n",
      "('confusion matrix\\n', array([[ 2260,  4916],\n",
      "       [ 1354, 37772]]))\n",
      "('\\nAverage accuracy: ', 0.86483665212445826)\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "import datetime\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "\n",
    "iter_num = 0\n",
    "accuracy = 0\n",
    "\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set predictions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print (\"====Iteration\",iter_num,\" ====\")\n",
    "    print (\"accuracy\", acc)\n",
    "    print (\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "    accuracy = accuracy + acc\n",
    "\n",
    "    print ('\\nAverage accuracy: ', accuracy/iter_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the above, accuracy is averageed around 86.5%.\n",
    "In previous work (mini-lab), we tested variations of L1 and L2, and changing other parameters, and it was approximately the same accuracy.\n",
    "\n",
    "### Couldn't Get Code to Work Past Here (THOMAS) --- FIXED (Rahn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import k-fold cross validation from scikit learn\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if 'health' in df_logreg:\n",
    "    y = df_logreg['health'].values # get the labels we want\n",
    "    del df_logreg['health'] # get ride of the class label\n",
    "    X = df_logreg.values # use everything else to predict!\n",
    "    \n",
    "    \n",
    "KFoldCrossObject = KFold(len(y), n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy:', 0.84868250539956802)\n",
      "[[ 1337  2760]\n",
      " [  743 18310]]\n",
      "(u'HLTHPLN1', 'has weight of', 0.10941210180101903)\n",
      "(u'_IMPRACE', 'has weight of', -0.11970276363268452)\n",
      "(u'_SMOKER3', 'has weight of', 0.19378876359378444)\n",
      "(u'MEDCOST', 'has weight of', 0.23031960233356977)\n",
      "(u'EDUCA', 'has weight of', 0.35610806026835989)\n",
      "(u'_AGE_G', 'has weight of', -0.5230897017438727)\n",
      "(u'_INCOMG', 'has weight of', 0.64486151092982669)\n",
      "(u'PHYSHLTH', 'has weight of', 0.73342638152453898)\n"
     ]
    }
   ],
   "source": [
    "for train_indices, test_indices in KFoldCrossObject: \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "# scale attributes by the training set\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "\n",
    "X_train_scaled = scale.transform(X_train) # apply to training\n",
    "X_test_scaled = scale.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "logReg = LogisticRegression(penalty='l2', C=0.05, n_jobs=-1) \n",
    "logReg.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = logReg.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(logReg.coef_.T,df_logreg.columns) # combine attributes\n",
    "zip_vars.sort(key = lambda t: np.abs(t[0])) # sort them by the magnitude of the weight\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAEvCAYAAAA9ypKHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucXWV97/HPZKJgmCEkOKlCKzEp/Lz1UFtsEQGveEVK\nvaDgBfGO0nIQKUXFS+1LrTmgKEWhHCyCF1osSrGAiIgI1KNiFfX4Q0ijtYpEZgyJASTD9I+1drIz\nmZmEnZ29npn9eb9eeWVd9p71m3lm79nftZ71PAMTExNIkiRJkso1r+kCJEmSJEkzM7hJkiRJUuEM\nbpIkSZJUOIObJEmSJBXO4CZJkiRJhTO4SZIkSVLh5nfypIgYAM4C9gXuAV6bmSvb9r8MeAuwAfhE\nZn68C7VKkiRJUl/q9Irb4cBOmXkAcApw+qT9K4CnAQcCJ0bEws5LlCRJkqT+1mlwOxC4AiAzvwHs\nN2n/d4FFwEPqdWf5liRJkqQOdRrcdgXWtK1viIj2r/UD4NvAzcBlmXlXh8eRJEmSpL7X0T1uwF3A\ncNv6vMy8HyAi/gB4HrAX8BvgUxHxwsz83ExfcMOG8Yn58wc7LEeSJEmSZr2B6XZ0GtyuBw4FLo6I\n/amurLWsAdYD92bmRETcQdVtckZjY+s7LKVMIyPDrF69tukyNAPbqHy2Udlsn/LZRuWzjcpm+5Rv\nrrXRyMjwtPs6DW6XAIdExPX1+jERcSSwS2aeGxHnAF+PiHuB24B/7PA4kiRJktT3OgpumTkBHDtp\n8y1t+88Gzt6OuiRJkiRJNSfgliRJkqTCGdwkSZIkqXAGN0mSJEkqnMFNkiRJkgpncJMkSZKkwhnc\nJEmSJKlwnc7jJu0Q4+PjrFq1sifHGhsbYnR03Q4/ztKlyxgcHNzhx5EkSdLcZXBTUVatWsnxKy5l\nwcIlTZfSFevX3MEZJx3G8uV7N12KJEmSZjGDm4qzYOEShhbt2XQZkiRJUjG8x02SJEmSCmdwkyRJ\nkqTCGdwkSZIkqXAGN0mSJEkqnMFNkiRJkgpncJMkSZKkwhncJEmSJKlwBjdJkiRJKpzBTZIkSZIK\nZ3CTJEmSpMIZ3CRJkiSpcPObLkCSpH4yPj7OqlUre3KssbEhRkfX7fDjLF26jMHBwR1+HEnqZwY3\nSZJ6aNWqlRy/4lIWLFzSdCldsX7NHZxx0mEsX75306VI0pxmcJMkqccWLFzC0KI9my5DkjSLeI+b\nJEmSJBWuoytuETEAnAXsC9wDvDYzV7btfwJwWr16O/DyzPztdtYqSZIkSX2p0ytuhwM7ZeYBwCnA\n6ZP2nwO8KjMPBq4A9uq8REmSJEnqb50GtwOpAhmZ+Q1gv9aOiNgHuBN4S0R8FVicmT/ezjolSZIk\nqW91Gtx2Bda0rW+IiNbXeijwROAjwDOAZ0TEUzquUJIkSZL6XKejSt4FDLetz8vM++vlO4FbM/MW\ngIi4guqK3Fdn+oKLFi1g/vy5NQfMyMjw1h+kzYyNDTVdQtctXjzk78J28GdXNtvngfN9TpP5syub\n7VO+fmmjToPb9cChwMURsT9wc9u+lcBQRCyrByw5CDh3a19wbGx9h6WUaWRkmNWr1zZdxqzTi4li\ne210dJ2/Cx3ydVQ226czvs+pna+jstk+5ZtrbTRTCO00uF0CHBIR19frx0TEkcAumXluRLwG+ExE\nANyQmZd3eBxJkiRJ6nsdBbfMnACOnbT5lrb9XwX+tPOyJEmSJEktTsAtSZIkSYUzuEmSJElS4Qxu\nkiRJklQ4g5skSZIkFc7gJkmSJEmFM7hJkiRJUuEMbpIkSZJUOIObJEmSJBXO4CZJkiRJhTO4SZIk\nSVLhDG6SJEmSVDiDmyRJkiQVzuAmSZIkSYUzuEmSJElS4QxukiRJklQ4g5skSZIkFc7gJkmSJEmF\nM7hJkiRJUuEMbpIkSZJUOIObJEmSJBXO4CZJkiRJhTO4SZIkSVLhDG6SJEmSVDiDmyRJkiQVbn4n\nT4qIAeAsYF/gHuC1mblyisedDdyZmW/briolSZIkqY91esXtcGCnzDwAOAU4ffIDIuINwOO2ozZJ\nkiRJEp0HtwOBKwAy8xvAfu07I+KJwBOAs7erOkmSJElSx8FtV2BN2/qGiJgHEBEPA94FHAcMbF95\nkiRJkqSO7nED7gKG29bnZeb99fKLgd2BfwMeDjwkIn6UmZ+c6QsuWrSA+fMHOyynTCMjw1t/kDYz\nNjbUdAldt3jxkL8L28GfXdlsnwfO9zlN5s+ubLZP+fqljToNbtcDhwIXR8T+wM2tHZn5UeCjABFx\nNBBbC20AY2PrOyylTCMjw6xevbbpMmad0dF1TZfQdaOj6/xd6JCvo7LZPp3xfU7tfB2VzfYp31xr\no5lCaKfB7RLgkIi4vl4/JiKOBHbJzHM7/JqSJEmSpCl0FNwycwI4dtLmW6Z43PmdfH1JkiRJ0iZO\nwC1JkiRJhTO4SZIkSVLhOr3HTZJUoPHxcVatWtmTY42NDfVkoI2lS5cxODi3Rh2WJOmBMrhJ0hyy\natVKjl9xKQsWLmm6lK5Yv+YOzjjpMJYv37vpUiRJapTBTZLmmAULlzC0aM+my5AkSV3kPW6SJEmS\nVDiDmyRJkiQVzuAmSZIkSYUzuEmSJElS4QxukiRJklQ4g5skSZIkFc7gJkmSJEmFM7hJkiRJUuEM\nbpIkSZJUOIObJEmSJBXO4CZJkiRJhTO4SZIkSVLhDG6SJEmSVDiDmyRJkiQVzuAmSZIkSYUzuEmS\nJElS4QxukiRJklS4+U0XIEmSVIrx8XFWrVrZs+ONjQ0xOrpuhx9n6dJlDA4O7vDjSNpxDG6SJEm1\nVatWcvyKS1mwcEnTpXTN+jV3cMZJh7F8+d5NlyJpO3QU3CJiADgL2Be4B3htZq5s238kcDxwH3Bz\nZr6pC7VKkiTtcAsWLmFo0Z5NlyFJm+n0HrfDgZ0y8wDgFOD01o6I2Bn4G+DJmXkQsFtEHLrdlUqS\nJElSn+o0uB0IXAGQmd8A9mvbdy9wQGbeW6/Pp7oqJ0mSJEnqQKfBbVdgTdv6hoiYB5CZE5m5GiAi\n/gLYJTO/vH1lSpIkSVL/6nRwkruA4bb1eZl5f2ulvgfug8DewAu25QsuWrSA+fN37GhH4+Pj3Hbb\nbTv0GC1jY7/oyXEAli9fPmdGihobG2q6hK5bvHiIkZHhrT9QU/Jn98D4GiqfbVS2udg+MLfaqNf8\nuZWvX9qo0+B2PXAocHFE7A/cPGn/OcDdmXn4tn7BsbH1HZay7W677ceOFFW4XgyJ3Gujo+tYvXpt\n02XMSiMjw/7sHiBfQ+Wzjco2F9sH5lYb9ZJ/h8o319pophDaaXC7BDgkIq6v14+pR5LcBfg2cAxw\nXURcA0wAZ2TmFzo8Vlc5UpQkSZKk2aaj4JaZE8Cxkzbfsr1fV5IkSZK0pU4HJ5EkSZIk9YjBTZIk\nSZIKZ3CTJEmSpMIZ3CRJkiSpcAY3SZIkSSqcwU2SJEmSCmdwkyRJkqTCGdwkSZIkqXAGN0mSJEkq\n3PymC5AkSZK21fj4OKtWrezJscbGhhgdXbfDj7N06TIGBwd3+HE0uxncJEmSNGusWrWS41dcyoKF\nS5oupSvWr7mDM046jOXL9266FBXO4CZJkqRZZcHCJQwt2rPpMqSe8h43SZIkSSqcwU2SJEmSCmdw\nkyRJkqTCGdwkSZIkqXAGN0mSJEkqnMFNkiRJkgpncJMkSZKkwhncJEmSJKlwBjdJkiRJKpzBTZIk\nSZIKZ3CTJEmSpMIZ3CRJkiSpcPM7eVJEDABnAfsC9wCvzcyVbfufD5wK3Ad8IjPP7UKtkiRJktSX\nOr3idjiwU2YeAJwCnN7aERHz6/VnAE8BXh8RI9tZpyRJkiT1rU6D24HAFQCZ+Q1gv7Z9jwZ+nJl3\nZeZ9wNeBg7erSkmSJEnqYx11lQR2Bda0rW+IiHmZef8U+9YCCzs8TtetX3NH0yV01Vz7fmBufU9z\n6XsBGB8fZ9WqlVt/YJeMjQ0xOrpuhx9n6dJlDA4O7vDj9Mpc+r2bS99Lu7n0fc2l76Vlrn1Pc+37\ngbn1Pc2l76Wll58X+umzQqfB7S5guG29Fdpa+3Zt2zcM/HprX3DRogXMn79jfxiLF+/LBe8f2qHH\naMLy5csb/0XqlrnYRnOpfW655RaOX3EpCxYuabqUrlm/5g4ueP9R7LPPPk2X0hW+hspnG5VtLrYP\n2Ealm0vtA3Pv80IpnxU6DW7XA4cCF0fE/sDNbfv+P/D7EbEbsJ6qm+SKrX3BsbH1HZbywCxa9PCe\nHGdkZJjVq9f25Fijo7352fXKXGujudQ+o6PrWLBwCUOL9my6lK4aHV3Xs9drL/gaKp9tVLZetQ/Y\nRp3yNVS2ufh5oVefFUZGhqfd12lwuwQ4JCKur9ePiYgjgV0y89yIeAvwJWAAODczf9HhcSRJkiSp\n73UU3DJzAjh20uZb2vZ/EfjidtQlSZIkSao5AbckSZIkFc7gJkmSJEmFM7hJkiRJUuEMbpIkSZJU\nOIObJEmSJBXO4CZJkiRJhTO4SZIkSVLhDG6SJEmSVDiDmyRJkiQVzuAmSZIkSYUzuEmSJElS4Qxu\nkiRJklQ4g5skSZIkFc7gJkmSJEmFm990AZIkSZLmlvVr7mi6hK4p5XsxuEmSJEnqmqVLl3HGSYf1\n5FiLFw8xOrpuhx9n6dJlO/wYW2NwkyRJktQ1g4ODLF++d0+ONTIyzOrVa3tyrKZ5j5skSZIkFc7g\nJkmSJEmFM7hJkiRJUuEMbpIkSZJUOIObJEmSJBXO4CZJkiRJhTO4SZIkSVLhOprHLSJ2Bi4ElgB3\nAUdn5p2THnMC8BJgAvi3zHzvdtYqSZIkSX2p0ytuxwLfy8yDgQuAU9t3RsQjgSMzc//MfCLwrIh4\n3PaVKkmSJEn9qdPgdiBwRb18OfCMSft/Cjy7bf1BwD0dHkuSJEmS+tpWu0pGxKuBE6i6PAIMALcD\na+r1tcCu7c/JzHFgtH7+CuCmzLy1SzVLkiRJUl/ZanDLzPOA89q3RcTngOF6dRj49eTnRcRO9fPW\nAG/a2nEWLVrA/PmD21Dy7DEyMrz1B6lRttEDMzY21HQJO8TixUP+LnTIn1v5bKPy2UZls33K1y9t\n1NHgJMD1wHOBb9X/XzfFYy4FvpyZK7blC46Nre+wlDKNjAyzevXapsvQDGyjB250dF3TJewQo6Pr\n/F3ogK+h8tlG5bONymb7lG+utdFMIbTT4PYx4PyIuA64FzgKNo4k+eP66x4EPCginkvVzfKUzPxG\nh8eTJEmSpL7VUXDLzLuBI6bY/qG21QWdFiVJkiRJ2sQJuCVJkiSpcAY3SZIkSSqcwU2SJEmSCmdw\nkyRJkqTCGdwkSZIkqXAGN0mSJEkqnMFNkiRJkgpncJMkSZKkwhncJEmSJKlwBjdJkiRJKpzBTZIk\nSZIKZ3CTJEmSpMIZ3CRJkiSpcAY3SZIkSSqcwU2SJEmSCmdwkyRJkqTCGdwkSZIkqXAGN0mSJEkq\nnMFNkiRJkgpncJMkSZKkwhncJEmSJKlwBjdJkiRJKpzBTZIkSZIKZ3CTJEmSpMLN7+RJEbEzcCGw\nBLgLODoz75zicQPAF4HPZ+Y521OoJEmSJPWrTq+4HQt8LzMPBi4ATp3mcX8L7NbhMSRJkiRJdB7c\nDgSuqJcvB54x+QER8UJgvO1xkiRJkqQObLWrZES8GjgBmKg3DQC3A2vq9bXArpOe81jgKOBFwDu7\nVawkSZIk9aOtBrfMPA84r31bRHwOGK5Xh4FfT3raK4E9gK8AS4F7I2JVZn5puuMsWrSA+fMHt73y\nWWBkZHjrD1KjbKMHZmxsqOkSdojFi4f8XeiQP7fy2Ubls43KZvuUr1/aqKPBSYDrgecC36r/v659\nZ2ae3FqOiHcBv5gptAGMja3vsJQyjYwMs3r12qbL0AxsowdudHRd0yXsEKOj6/xd6ICvofLZRuWz\njcpm+5RvrrXRTCG00+D2MeD8iLgOuJeqWyQRcQLw48y8rMOvK0mSJEmapKPglpl3A0dMsf1DU2x7\nTyfHkCRJkiRVnIBbkiRJkgpncJMkSZKkwhncJEmSJKlwBjdJkiRJKpzBTZIkSZIKZ3CTJEmSpMIZ\n3CRJkiSpcAY3SZIkSSqcwU2SJEmSCmdwkyRJkqTCGdwkSZIkqXAGN0mSJEkqnMFNkiRJkgpncJMk\nSZKkws1vugBJs8v6NXc0XUJXzbXvR5IkzU0GN0nbbOnSZZxx0mE9O97ixUOMjq7b4cdZunTZDj+G\nJEnS9jC4Sdpmg4ODLF++d8+ONzIyzOrVa3t2PEmSpFJ5j5skSZIkFc7gJkmSJEmFM7hJkiRJUuEM\nbpIkSZJUOIObJEmSJBXO4CZJkiRJhetoOoCI2Bm4EFgC3AUcnZl3TnrMc4B31qvfzszjtqdQSZIk\nSepXnV5xOxb4XmYeDFwAnNq+MyKGgA8Cz8vMJwKrImL37apUkiRJkvpUp8HtQOCKevly4BmT9h8A\n3AycHhFfA345+YqcJEmSJGnbbLWrZES8GjgBmKg3DQC3A2vq9bXArpOe9lDgKcC+wHrguoi4MTNv\n7ULNkiRJktRXthrcMvM84Lz2bRHxOWC4Xh0Gfj3paXcC38zM1fXjvwb8ITBtcBsZGR7Y9rJnh5GR\n4a0/SI2yjcpnG5XN9imfbVQ+26hstk/5+qWNOu0qeT3w3Hr5ucB1k/bfBDwuIhZHxHxgf+CHHR5L\nkiRJkvpaR6NKAh8Dzo+I64B7gaMAIuIE4MeZeVlEnAJ8iaqL5UWZaXCTJEmSpA4MTExMbP1RkiRJ\nkqTGOAG3JEmSJBXO4CZJkiRJhTO4SZIkSVLhDG6SJEmSVDiDmyRJkiQVrtPpANQmInYBXks1EflX\ngAuAceBNmZlN1ibNFhGxW2b+OiJeAAxRTSXy2cy8r+HSpOJFxK7ASZl5aj1Vz+8C9wMvyszvNFud\nJG2/iBjIzC2Gw4+IvTLzJ03U1GteceuOC4HdgIOAa4D3Am8DzmyyKG0SEY+Y7l/TtQki4nDgy/Xq\nO4FHAy8D/ndjRWmbRMTuEfHXTdchPgz8ql4eBx4FHAe8o7GKtIWIOKbpGqRZ7OrWQkSsaNv+iQZq\naYRX3LpjcWa+JyLmATdn5tUA9brKcBHVFZwBqlDww3p5AjigwbpU+QvgWfXyWGaeEhELgauAFdM/\nTU2JiCdQBYNnARc3XI7gkZn56np5IjPvBS6PiHc3WJO29Ar66EPmbBMRD55uX2b+tpe1aEoDbct/\nPM32Oc3g1h33RcTLMvNTEbEvQEQ8Ba9oFiMzn9hajohrMvOpTdajLczLzDvr5WsBMnNNRKxvsCZN\nUn+oORJ4M3AvsCtVYLi70cIEMNi23H5VZ12vC9GMFkTE3kzxQTMzb2mgHm3uZuB3gFE2ndxt/b+s\nwbq0pfbX0BbdJ+cqg1t3vBw4GfhUZm6ot70YeENzJWkGffMCn0Ue0lrIzHe3bR/c8qFq0CrgM8DL\nMvPHEXG5oa0Yv42Ih2Xm7Zm5CiAiHgZsmPlp6rEAzmbL4DYBPK335WiSA4Ergadn5ljTxWgLE9Ms\n9w2DWxdk5u3ACZO2vTkingN4Bk3auhsj4rjM3HhfaES8EbixwZq0pQ9T3Xu4NCLOpY+6p8wCHwAu\ni4i/BW6lujrwduCkRqvSZP+RmQa0QmXm6vqe3T+i7X4qFeOPI+IGqr89j2lbfnSzZfXOwMREXwbW\nroqIVwHvA+4GXgSsBP4BeHRm/kGDpakWEa9vWz0ROK21kpnn9L4itYuIBcB5wD5Ur59H1v+/0is6\n5YmIJ1ONpPtc4Fzggsz8frNVqe6q/waq189/AR/PzJuarUrt7KovdS4i9ppuX7+MKukVt+54C/BY\n4OFUgWAP4AtUZ6ZVhoe3LX+6bd0zFwXIzPXASyPid4ClwM8y879b+yPiTzPzG03Vp81l5rXAtRGx\nG1VX8QuAxzdblTLzu8Cbmq5DM3px+0r9GhrPzLUN1aM2EfHK6fZl5id7WYu2lJk/qU/En5eZGyLi\nIOCxmfnxpmvrFYNbd4zWfaHHIuIxwBsz8/Kmi9JmfpqZjuRVuMz8JfDLKXa9H+//KEJEPBO4qp5L\nZy/g1sw0tDUsIu6nGlChfeS7AaoRJvdopipN4RERcRXwJ8DzgY9TfXZ4a2b+a7OliS273A1QDfaz\nHjC4NaweJfdxVNNwbaDqWXBCRIxk5nubrK1XDG7dcX/b8k8MbUVyCObZzXupChARx1K9lm4E1lJd\nsX5XRDzCLseNeyvwHOA2qoGyrmu4Hk1tBXB0Zt5X34/4bKp7Ei8HDG4Ny8xTWssRsRw4H7gM5xQt\nxXOA/VuTcGfmqoh4CXAD1RzKc57BrTt2j4hDqIb/37U+Iw1AZn6pubLUZheHYJ7V7NJahlcBT87M\newAy83v1e981gMGtQZl5OnB6RDwKeFl9ZvoG4MLMzEaLU7vB+nWzB7BL6x7E+oqpChERb6YKaydk\n5mVN16ON1rVCW0t9EqRvuhob3LrjJuCoevk7VPMcQfVh0+BWhn1wCGZpe61vhbaWzFzXT380S5eZ\nPwJOjYjfpbrn+rvAzs1WpTb31f8/G/gyQEQ8CBhurCJtFBF7UvXOGQX+xCkBinN3RCzLzJWtDRGx\njD46uWtw64LMPGaq7RGxU69r0bQcgnl2s6tkGe6LiIdm5q9aGyLiofi3pAgRsRg4ov4HcBFwbHMV\naQpfjojrgd8DDqu7451J1VZq3g+Ae4GvAH8fERt3ZOZR0z1JPXMy8PmIuJpq5OlHAM+i6g3SF/xj\n2wURcVFmvqRePjEzW0PNX45Xc6SORcROmXkv1Uigat57gS9FxPls+qP5GuCvGq1KRMS/AXsC/wy8\njuqmfRUmM/8uIi4F1mTmz+vgdk5mXtJ0bQLgz5ouQNPLzB/UI0n+GdUI7jcBf9NPo7LOa7qAOWJJ\n2/Lz2pa9SlCOF0+1sX4DUMMi4qK25RPbdl0OkJn/0POitIV6wIsXAgup3ut2Bf48M7/caGECeAxV\ne7yGqgvej4Cs/1dZfgYcEhHvBA7CiZ6LkZnXTvWPzT/bqUGZuSYzP5mZH6AaOOZVEfHDpuvqFa+4\ndV97WOubPrela+/aNclpVMMyq1mTT360rlp78qMgEfEIYBz4R6r3t7tneG2phzJzadM1aOvqQbI+\nD1wK/CfVHLAnR8ThDiJTtKc0XYA2qafeOo7qpPy/AEc3W1HvGNy6Y2KaZZXPYFAeT36U6yI2b5Ph\niHgw8EonSG9eRLyQ6sPMXsBPgTMz8+Jmq9Ik/wc4MjO/19oQEZ+ptz+/saqkWaB+j3sz8GCqQWQi\nM9/QbFW9ZXDrjsdGxKepPnC2Lz+m2bK0DQwGZfDkxyyQmU+cvK2+R+cTwMG9r0gtEfEK4CVUg5Gs\npBpJ94MRMZyZzmFZjoXtoQ0gM2+KiEVNFaRNImKfKTYP4MispfgkcAZwWmbeWQe5vmJw644j2pY/\nPs2yGhQRN7JlIBgAHtVAOdqSJz9mqcy8LSIM2817HXBIPZgPwPcj4gjgSqpgrTJM18vDz2NlOHua\n7Xf2tApN5/eBY4DrIuJm4KEN19NzvlF0x56ZudmodxGxM/D3wLXNlKRJXtp0AZqRJz9mqYgYpBqs\nRM3a0BbagI1z7I03VZCm9J2IeHNm/n1rQ0QcC3y7wZpUy8ynNl2DppeZvwDeB7wvIp4OvC4i/hP4\nXGa+tdnqesPg1h1/FRFrM/NfYeOl9ouBf2+2LLV58gz7PtmzKjSlzLw2InbLzF9HxAuAIaorpJ9t\nuDS1iYjXT9q0E3AY1WALatZgRAxl5rrWhogYBgYbrElbejvwDxHxBuA2YClwK/DKJotSJSJeBHwI\nWA+8PDO/2XBJmkZmXg1cHRG7A5P/Ns1ZBrfueDZwZUSsAx4GfAB4S2Z+rtmy1ObRbctHAp+pl+3i\nVYCIOBx4B7Af8E6qaQAeT/V6WtFgadrcwyet3w38ndMBFOFM4JKIOJlNgWBFvV2FyMzfAEfVHzaX\nAT/PzP9uuCxtcgLwv4BFwIepTkypEBGxF3AiMEb1t2c91cjgrwHe32RtvTIwMeHn1m6IiD2Bq4Df\nUM1r9LOGS9I0IuIau0OUJSKuBo6obza+JjOfGhELgasy0+kaChMRy6juLfhZZv686XpUiYhnUY0q\nuYxqrrCPZuZlzValdhHxIOA9VJMG3xMRhwIHAu/IzA3NVqeI+EpmPq1evjozn950TdokIm6gmo5m\nL6oeH78FXgC8NjO/3mBpPeMVty6oh8NeTTWT+z8DIxFxB0Bm/rbJ2jQlz1aUZ15mtm7+vhaqSTYj\nYn2DNWmSiFgK/BPVH8s7gL0i4jfAS+p7D9SsL2fmlbCxm+TdDdejLX0I2ADcX6/fADwTOB34y6aK\n0pScLqg892fmOQD1vW1fA/4wM+9ptqzeMbh1R1KFgdaL/F/q/yeoznxKmtlDWguZ+e627d6fU5bT\nqbqBbzyzGRGHUA3E9ILGqhIR8Tjg8xHxhMwcA54OnBYRz8/MHzZcnjb54/ZpNTJzNCKOB5wHsQzL\nI+J9VJ/nWssAZObbmitLtfvalkeBV2VmX52MN7h1QWY+sukaNLN6gtNWuG4NNw9AZh7VWGFquTEi\njsvMjffjRMQbgRsbrElbGpncHSUzr6rvq1KzzgBeWoc2MvPzdc+PjwDPaLQytdviKmhmTtRXrtW8\nd06zrDK0h7Q1/RbawODWNfUkgMdR9bv9KXBmZl7cbFVq4xDzZXs7cF5EvJpq8uBH1v870lpZ7ptm\n+7yeVqGpzMvMb7VvyMwb6q78KsfqiNivva0iYj+qUQzVvGuaLkAzOjAifk51En5x2/JEZu7RbGm9\nYXDrgoh4BfAS4FiqD5v7AB+MiOHMdOLTAtTDze+bmd+tP8i8DrgXOK/h0gTUI0O9NCJ+h2o0vJ9l\n5n/Xg/444lo5do+IZ07aNgAsbqIYbWa6bsUP6mkV2poTgS9ExE+pPi88guo978VNFqWNLmJT75xH\nAz+slyeAAxqsS0Bm9v2JKEeV7IKI+BpwSPvkpxExBFyZmU9qrjK1RMRbqML1k4DTqK6M/gQgM49v\nsDRNISLqOmBmAAAHUElEQVSeSnUF+0mZ+bCm61ElItpPRLXf17tzZh7ZQEmqRcQpwO7Ae+uBfYaA\ndwP3ZubbGy1Om4mIeVQjSe5B9Xfo3/uxy1fpHIG6PBHxaOC9wDrg5Mz8ZcMl9ZxX3LpjQ3toA8jM\ndREx3lRB2sKLqc6WTQBHAXvXkz3f0GxZaomIXYBXUV25fhjwF1RtpXIsyMyXAETEiZl5Wr38lWbL\nEtX8oScDN0XEAqob9z+J8yCW6HFU9x0+lGrahtVUk3CrLIbp8nyM6r1uMfBB4Ohmy+k9g1t3DEbE\nUGaua22oh2J2RLxyrM3M8Yj4I2BlZv663u5wvwWIiI8CTwMuAf4c+EhmfmbmZ6kBI23Lz6O6eq0C\n1FdsPlD/U6Ei4sVUAfts4FtUvT/+JSJOzcwvNFqcVL77M/MKgPqe+L5jcOuOM4FL6pHVbqPqr76i\n3q4yTETEPlRXdC4FiIi9qebTUfMOBL5NNST2bXims1QD0yyrYXU31ilfN5nZlx9wCnU88OTM3DiK\nZEScD3yh/qcGRcTr21b3bF9vzR+mYvTloFgGty7IzH+OiLuA91DN2/YzqisGlzVbmdqcClwA3A68\nLSKeDFyIN4QXITMfHxEHUA0aczowEBGPyswfNVyaNjcxzbKa99lJ63tQXX37+hSPVXM2tIc2gMy8\ny1srivHwtuVPt637fleG1gBZrVElNw6WlZlfaq6s3jG4dUlmXglc2XQdmtb3M/NPWysR8e/Assyc\nbnhz9Vhm3gDcUHczfjlwYUSQmftFxLsy8z0Nl6hNcyAOTFp+TLNlqf4bBEBEHAm8AzgxMy9sripN\n4f5ptvfl1YMC/dTRwIv2HeDIKZYnAIObtk1E/Cdbno1pzSuxrIGStKVvRsTRrblzJg8mo3Jk5lqq\nG5A/FhGPrzc/ucGStMkRbcvOjViYiFhM1Ra7AgdnplNplKd1wqOdJz/K8QrA4FaozHxV0zU0zeDW\nHf8K7AdcBXyKeph5FeUVwDkRcQnwPodenh0y8zv1ovdTFSAzr226Bk0tIp5P1c34tMw0SJfriGm2\n22Zl2KW+/32LvzmZeUsD9ahNRKycYnNfXSgxuHVBZv5lPS/LM6m6pywGPg/8E9Ukz2pYZt4UEU+k\nGs3ryoi4uG2fNxyXz6AtzewLwHrgXRHxznpb6wPNHs2VpUnuajshtVFE/FkTxWgL+1CN+Dk5uE1Q\njXysZl3GpgslFwI/bbac3jO4dUlm3g9cAVxRd1f5GPARYEGjhandPGAXqiHNveFY0pyRmd4jNTuc\nRh0AIuKqzDyk3n48jipZgv/ITANaoSZdKDmVPrxQYnDrkvoX6RCqGyX/ELgc+JNGi9JG9dW2/wt8\nEdjfe9xmHbtKSjOYNIz5ZuxVUJT297L502yXNI1+v1BicOuCiDgLOBj4KnBOPTqeynIB8OrM/FrT\nhagjr2y6AKlwD59m+wSAI7MWY7opNez9UYYppwiKiIMy87peF6Mt9fuFEoNbd7wRuBN4IfDCiJjA\newtKs+/kuXM0e2TmfzVdg1SybQhljsxahnkR8SCqrvubLTdblgAy81fT7DqNPgoHpfJCicGtK7y3\nYFa4tS1QLwJGMVxL6h92xSvDXkDWywNtyyqbr58y9P2FEoNbF0TETlS/TB8B9gA+THWT5Fsz8/Ym\na1MlMzd2I4qIazLzqU3WI0k9Zle8MnyVqi2mGrVQ5bJ9CuCFEoNbt5wJrKXq6nAW8E3gB1Q3TP55\ng3Vpar4BS5Ka8EdUgyh8Cmh18/JqTiEi4ka2/IwwADyqgXI0iYMwGdy65TGZ+aSI2Bk4CHhRZt4X\nESc2XZgkSRgOipCZ+0bE44CXA38NfA24MDNvbbYy1aabCN0TvmXo+0GYDG7dsbb+/0nA/8vM++r1\nhzRUjyaJiGfWiwPA7m3rZOaXmqlKknrGkVkLkZnfpwptRMTBwPsj4vcyc/9mKxPVlbVWV9YjgU/X\nywa3AjgIk8GtW9bVl29fBHy6Hqr0ZfThjO4FOxJYCGwAbqrXoXozNrhJmtMcmbUsETEMvIDqb9Eu\nwIXNViSAzDyltRwR+2fm25qsRw/YnO9ZYHDrjjcCJ1FNCHg+8DSqEPcG6I9Lt7PAt4ETgXHguMy8\nouF6JEl9JiKOAF5KNbrk54A3ZuaqRovSdLzKNvvM+TYzuHVBPe/HyW2brq7/tcz5S7ezwFHAPlRX\n3S6gCtmSJPXSZ4EfAd8F/gB4X0QAkJlHNViXpFnA4NYbc/7S7SxwT33v4a8i4sFNFyNJ6ktORVOw\niPgMm+5xe2xEfLq1z2A9K8z5z9sGt96Y85duZ5k5/8KWJJUnM69tugbN6OPTLGt2mPODMA1MTJgp\ndrSI+EpmPq3pOvpZRPySqvvqANU9iBu7snoWTZIkSaXziltveIWneUe0LXsWTZIkSbOKwa035vyl\n29LZPUWSJEmzmV0lJUmSJKlw85ouQJIkSZI0M4ObJEmSJBXO4CZJkiRJhTO4SZIkSVLhDG6SJEmS\nVLj/ARAyMpmZCbD5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x37d3d9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "\n",
    "weights = pd.Series(logReg.coef_[0],index=df_logreg.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
