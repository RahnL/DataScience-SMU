{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining - MSDS 7331 - Thurs 6:30, Summer 2016\n",
    "Team 3 (AKA Team Super Awesome):  Sal Melendez, Rahn Lieberman, Thomas Rogers\n",
    "\n",
    "\n",
    "Github page:\n",
    "https://github.com/RahnL/DataScience-SMU/tree/master/DataMining\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Data Mining - Mini Lab 1\n",
    "\n",
    "\n",
    "- Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = pd.read_csv(\"data/LLCP2014XPT.txt\", sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the Variables of Interest\n",
    "We are most interested to know how the variables in our dataset relate to self-reported health quality.\n",
    "\n",
    "We'll work to reduce the dataset and create an imputed variable from the self-reported measure of health. The question of interest is, \"Would You Say in General That Your Health is: (1) excellent, (2) very good, (3) good, (4) fair, (5) poor.\" Choices 7 and 9 were \"unsure\" and \"not asked\", respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_reduced = df[['_AGE80','GENHLTH','_INCOMG', '_SMOKER3']]\n",
    "\n",
    "# this creates a new variable by categorizing GENHLTH into three categories\n",
    "#df_reduced['health'] = pd.cut(df_reduced.GENHLTH,[0,2,5,9],3,labels=[0,1,2]) \n",
    "\n",
    "df_reduced.head()\n",
    "df_reduced.info()\n",
    "df_reduced.describe().transpose()\n",
    "\n",
    "df_reduced.dropna(inplace=True) # this drops those empty variables\n",
    "\n",
    "# Genhlth, _incomg, _smoker3 are all categorical and integer already, so one-hot-encoding is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training And Testing\n",
    "\n",
    "Threefold cross validation, using 80% of data as training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(464660, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "#... setup x, y\n",
    "#if '_Age80' in df_reduced:\n",
    "y = df_reduced['_AGE80'].values # get the labels we want\n",
    "del df_reduced['_AGE80'] # get rid of the class label\n",
    "X = df_reduced.values # use everything else to predict!\n",
    "\n",
    "# do the cross validation\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print (cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression and stuff...\n",
    "\n",
    "Do a logistic regression on our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print (\"====Iteration\",iter_num,\" ====\")\n",
    "    print (\"accuracy\", acc) \n",
    "    print (\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Go do a support vector machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
