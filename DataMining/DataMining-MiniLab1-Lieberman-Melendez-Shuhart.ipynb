{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data Mining - MSDS 7331 - Thurs 6:30, Summer 2016\n",
    "\n",
    "Team 3 (AKA Team Super Awesome):  Sal Melendez, Rahn Lieberman, Thomas Rogers\n",
    "\n",
    "Github page:\n",
    "https://github.com/RahnL/DataScience-SMU/tree/master/DataMining\n",
    "\n",
    "(Note: Code borrowed heavily from Eric Larson's github pages for this class.\n",
    "https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb)\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Data Mining - Mini Lab 1\n",
    "\n",
    "\n",
    "- Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahnl\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (120) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENUM</th>\n",
       "      <th>...</th>\n",
       "      <th>_FOBTFS</th>\n",
       "      <th>_CRCREC</th>\n",
       "      <th>_AIDTST3</th>\n",
       "      <th>_IMPEDUC</th>\n",
       "      <th>_IMPMRTL</th>\n",
       "      <th>_IMPHOME</th>\n",
       "      <th>RCSBRAC1</th>\n",
       "      <th>RCSRACE1</th>\n",
       "      <th>RCHISLA1</th>\n",
       "      <th>RCSBIRTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1172014</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000001</td>\n",
       "      <td>2014000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1072014</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000002</td>\n",
       "      <td>2014000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1092014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000003</td>\n",
       "      <td>2014000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1072014</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000004</td>\n",
       "      <td>2014000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1162014</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000005</td>\n",
       "      <td>2014000005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  FMONTH    IDATE  IMONTH  IDAY  IYEAR  DISPCODE       SEQNO  \\\n",
       "0       1       1  1172014       1    17   2014      1100  2014000001   \n",
       "1       1       1  1072014       1     7   2014      1100  2014000002   \n",
       "2       1       1  1092014       1     9   2014      1100  2014000003   \n",
       "3       1       1  1072014       1     7   2014      1100  2014000004   \n",
       "4       1       1  1162014       1    16   2014      1100  2014000005   \n",
       "\n",
       "         _PSU  CTELENUM    ...     _FOBTFS  _CRCREC  _AIDTST3  _IMPEDUC  \\\n",
       "0  2014000001       1.0    ...         2.0      1.0       2.0         5   \n",
       "1  2014000002       1.0    ...         2.0      2.0       2.0         4   \n",
       "2  2014000003       1.0    ...         2.0      2.0       2.0         6   \n",
       "3  2014000004       1.0    ...         2.0      1.0       2.0         6   \n",
       "4  2014000005       1.0    ...         2.0      1.0       2.0         5   \n",
       "\n",
       "   _IMPMRTL  _IMPHOME  RCSBRAC1  RCSRACE1  RCHISLA1  RCSBIRTH  \n",
       "0         1         1       NaN       NaN       NaN       NaN  \n",
       "1         1         1       NaN       NaN       NaN       NaN  \n",
       "2         1         1       NaN       NaN       NaN       NaN  \n",
       "3         3         1       NaN       NaN       NaN       NaN  \n",
       "4         1         1       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = pd.read_csv(\"data/LLCP2014XPT.txt\", sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the Variables of Interest\n",
    "We are most interested to know how the variables in our dataset relate to self-reported health quality.\n",
    "\n",
    "We'll work to reduce the dataset and create an imputed variable from the self-reported measure of health. The question of interest is, \"Would You Say in General That Your Health is: (1) excellent, (2) very good, (3) good, (4) fair, (5) poor.\" Choices 7 and 9 were \"unsure\" and \"not asked\", respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahnl\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 464664 entries, 0 to 464663\n",
      "Data columns (total 5 columns):\n",
      "_AGE80      464664 non-null int64\n",
      "GENHLTH     464660 non-null float64\n",
      "_INCOMG     464664 non-null int64\n",
      "_SMOKER3    464664 non-null int64\n",
      "health      464660 non-null category\n",
      "dtypes: category(1), float64(1), int64(3)\n",
      "memory usage: 14.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahnl\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_reduced = df[['_AGE80','GENHLTH','_INCOMG', '_SMOKER3']]\n",
    "\n",
    "# this creates a new variable by categorizing GENHLTH into three categories\n",
    "\n",
    "# default='warn' Turning off warnings for the following statements, since we're copying vaues, not overwriting\n",
    "# pd.options.mode.chained_assignment = None \n",
    "\n",
    "df_reduced['health'] = pd.cut(df_reduced.GENHLTH,[0,2,5,9],3,labels=[0,1,2]) \n",
    "\n",
    "df_reduced.head()\n",
    "df_reduced.info()\n",
    "df_reduced.describe().transpose()\n",
    "\n",
    "df_reduced.dropna(inplace=True) # this drops those empty variables\n",
    "\n",
    "# Genhlth, _incomg, _smoker3 are all categorical and integer already, so one-hot-encoding is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training And Testing\n",
    "\n",
    "Threefold cross validation, using 80% of data as training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(464660, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "#... setup x, y\n",
    "#if '_Age80' in df_reduced:\n",
    "y = df_reduced['health'].values # get the labels we want\n",
    "del df_reduced['health'] # get rid of the class label\n",
    "del df_reduced['_AGE80'] # We renamed this to 'health'\n",
    "\n",
    "X = df_reduced.values # use everything else to predict!\n",
    "\n",
    "# do the cross validation\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print (cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression and stuff...\n",
    "\n",
    "Do a logistic regression on our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Starting: ', datetime.datetime(2016, 6, 17, 21, 51, 32, 421000))\n",
      "('====Iteration', 0, ' ====')\n",
      "('accuracy', 0.99661042482675499)\n",
      "('confusion matrix\\n', array([[46852,     0,     0],\n",
      "       [    0, 45765,     0],\n",
      "       [    0,   315,     0]]))\n",
      "('Ending: ', datetime.datetime(2016, 6, 17, 21, 51, 35, 843000))\n",
      "('Elapsed Time: ', datetime.timedelta(0, 3, 422000))\n",
      "('Starting: ', datetime.datetime(2016, 6, 17, 21, 51, 35, 863000))\n",
      "('====Iteration', 1, ' ====')\n",
      "('accuracy', 0.99638445314853874)\n",
      "('confusion matrix\\n', array([[46696,     0,     0],\n",
      "       [    0, 45900,     0],\n",
      "       [    0,   336,     0]]))\n",
      "('Ending: ', datetime.datetime(2016, 6, 17, 21, 51, 39, 290000))\n",
      "('Elapsed Time: ', datetime.timedelta(0, 3, 427000))\n",
      "('Starting: ', datetime.datetime(2016, 6, 17, 21, 51, 39, 306000))\n",
      "('====Iteration', 2, ' ====')\n",
      "('accuracy', 0.9965996642706495)\n",
      "('confusion matrix\\n', array([[46661,     0,     0],\n",
      "       [    0, 45955,     0],\n",
      "       [    0,   316,     0]]))\n",
      "('Ending: ', datetime.datetime(2016, 6, 17, 21, 51, 42, 588000))\n",
      "('Elapsed Time: ', datetime.timedelta(0, 3, 282000))\n",
      "('\\r\\nAverage accuracy: ', 0.99653151408198104)\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "import datetime\n",
    "\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num = 0\n",
    "accuracy = 0\n",
    "\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "\n",
    "    starttime = datetime.datetime.now() \n",
    "    print('Starting: ', starttime)\n",
    "    \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print (\"====Iteration\",iter_num,\" ====\")\n",
    "    print (\"accuracy\", acc) \n",
    "    print (\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "    accuracy = accuracy + acc\n",
    "    \n",
    "    endtime = datetime.datetime.now()\n",
    "    print('Ending: ', endtime)\n",
    "    print('Elapsed Time: ', endtime - starttime)\n",
    "    \n",
    "print('\\r\\nAverage accuracy: ', accuracy/iter_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice the last line above, giving the average accuracy for all the iterations.\n",
    "\n",
    "### Interpretation of Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'GENHLTH', 'has weight of', -14.312749236918757)\n",
      "(u'_INCOMG', 'has weight of', 0.158108221371659)\n",
      "(u'_SMOKER3', 'has weight of', 0.21878865726956556)\n"
     ]
    }
   ],
   "source": [
    "weights = lr_clf.coef_.T # take transpose to make a column vector\n",
    "variable_names = df_reduced.columns\n",
    "for coef, name in zip(weights,variable_names):\n",
    "    print(name, 'has weight of', coef[0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attribute weights need to be normalized so they make sense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy:', 0.9965996642706495)\n",
      "[[46661     0     0]\n",
      " [    0 45955     0]\n",
      " [    0   316     0]]\n",
      "(u'GENHLTH', 'has weight of', -13.497189073384904)\n",
      "(u'_INCOMG', 'has weight of', 0.066835057624689026)\n",
      "(u'_SMOKER3', 'has weight of', 0.016556435334804796)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,df_reduced.columns) # combine attributes\n",
    "\n",
    "# This sorting breaks things, and can't figure out why\n",
    "# zip_vars.sort(key = lambda t: np.abs(t[0])) # sort them by the magnitude of the weight\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEwCAYAAAC5Y7qaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4257b320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=df_reduced.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it would make sense to remove variables that are highly related to one another or ones that are irrelevant and keep going with the weights analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEwCAYAAAC5Y7qaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x100c31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can also apply the StandardScaler function insied of the validation loop \n",
    "#  but this requires the use of PipeLines in scikit. Here is an example, but we will go over more \n",
    "#  thorough examples later in class\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) \n",
    "\n",
    "# create the pipline\n",
    "piped_object = Pipeline([('scale', std_scl), ('logit_model', lr_clf)])\n",
    "\n",
    "# run the pipline corssvalidated\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object):\n",
    "    piped_object.fit(X[train_indices],y[train_indices])  # train object\n",
    "    \n",
    "# it is a little odd getting trained objects from a  pipeline:\n",
    "trained_model_from_pipeline = piped_object.named_steps['logit_model']\n",
    "\n",
    "# now look at the weights\n",
    "weights = pd.Series(trained_model_from_pipeline.coef_[0],index=df_reduced.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n",
      "[[46459     0     0]\n",
      " [    0 46129     0]\n",
      " [    0     0   344]]\n"
     ]
    }
   ],
   "source": [
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.05, kernel='linear', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print 'accuracy:', acc \n",
    "print conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135L, 3L)\n",
      "(135L,)\n",
      "[53 65 17]\n"
     ]
    }
   ],
   "source": [
    "# look at the support vectors\n",
    "print svm_clf.support_vectors_.shape\n",
    "print svm_clf.support_.shape\n",
    "print svm_clf.n_support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.27974498e+00   4.44089210e-16   0.00000000e+00]\n",
      " [ -4.55948816e-01   0.00000000e+00   0.00000000e+00]\n",
      " [ -1.13987213e+00   2.77555756e-17   6.31836905e-08]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x34809be0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEwCAYAAABbv6HjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x47b1feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if using linear kernel, these make sense to look at (not otherwise, why?)\n",
    "print svm_clf.coef_\n",
    "weights = pd.Series(svm_clf.coef_[0],index=df_reduced.columns)\n",
    "weights.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ***  NEED TO CHANGE THIS FOR OUR DATA\n",
    "\n",
    "# Now let's do some different analysis with the SVM and look at the instances that were chosen as support vectors\n",
    "\n",
    "# now lets look at the support for the vectors and see if we they are indicative of anything\n",
    "# grabe the rows that were selected as support vectors (these are usually instances that are hard to classify)\n",
    "\n",
    "# make a dataframe of the training data\n",
    "df_tested_on = df_reduced.iloc[train_indices] # saved from above, the indices chosen for training\n",
    "# now get the support vectors from the trained model\n",
    "df_support = df_tested_on.iloc[svm_clf.support_,:]\n",
    "\n",
    "df_support['Survived'] = y[svm_clf.support_] # add back in the 'Survived' Column to the pandas dataframe\n",
    "df_imputed['Survived'] = y # also add it back in for the original data\n",
    "df_support.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now lets see the statistics of these attributes\n",
    "from pandas.tools.plotting import boxplot\n",
    "\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = df_support.groupby(['Survived'])\n",
    "df_grouped = df_imputed.groupby(['Survived'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = ['Age','Pclass','IsMale','FamilySize']\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde() \n",
    "    plt.legend(['Perished','Survived'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde() \n",
    "    plt.legend(['Perished','Survived'])\n",
    "    plt.title(v+' (Original)')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
